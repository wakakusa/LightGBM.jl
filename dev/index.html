<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · LightGBM.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">LightGBM.jl</span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/wakakusa/LightGBM.jl/blob/master/docs/src/index.md#L" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="LightGBM.jl-1"><a class="docs-heading-anchor" href="#LightGBM.jl-1">LightGBM.jl</a><a class="docs-heading-anchor-permalink" href="#LightGBM.jl-1" title="Permalink"></a></h1><ul><li><a href="#LightGBM.LGBMBinary-Tuple{}"><code>LightGBM.LGBMBinary</code></a></li><li><a href="#LightGBM.LGBMMulticlass-Tuple{}"><code>LightGBM.LGBMMulticlass</code></a></li><li><a href="#LightGBM.LGBMRegression-Tuple{}"><code>LightGBM.LGBMRegression</code></a></li><li><a href="#LightGBM.cv-Union{Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2},Array{Ty,1},Any}} where Ty&lt;:Real where TX&lt;:Real"><code>LightGBM.cv</code></a></li><li><a href="#LightGBM.fit-Union{Tuple{Ti}, Tuple{Tw}, Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2},Array{Ty,1},Vararg{Tuple{Array{TX,2},Array{Ty,1}},N} where N}} where Ti&lt;:Real where Tw&lt;:Real where Ty&lt;:Real where TX&lt;:Real"><code>LightGBM.fit</code></a></li><li><a href="#LightGBM.formattedclassfit-Tuple{Array,Array}"><code>LightGBM.formattedclassfit</code></a></li><li><a href="#LightGBM.loadmodel-Tuple{LGBMEstimator,String}"><code>LightGBM.loadmodel</code></a></li><li><a href="#LightGBM.metaformattedclassresult-Tuple{Array,Array}"><code>LightGBM.metaformattedclassresult</code></a></li><li><a href="#LightGBM.metaformattedclassresult-Tuple{Array{T,2} where T}"><code>LightGBM.metaformattedclassresult</code></a></li><li><a href="#LightGBM.predict-Union{Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2}}} where TX&lt;:Real"><code>LightGBM.predict</code></a></li><li><a href="#LightGBM.predict2-Union{Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2}}} where TX&lt;:Real"><code>LightGBM.predict2</code></a></li><li><a href="#LightGBM.savemodel-Tuple{LGBMEstimator,String}"><code>LightGBM.savemodel</code></a></li><li><a href="#LightGBM.search_cv-Union{Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2},Array{Ty,1},Any,Any}} where Ty&lt;:Real where TX&lt;:Real"><code>LightGBM.search_cv</code></a></li></ul><article class="docstring"><header><a class="docstring-binding" id="LightGBM.LGBMBinary-Tuple{}" href="#LightGBM.LGBMBinary-Tuple{}"><code>LightGBM.LGBMBinary</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">LGBMBinary(; [num_iterations = 10,
              learning_rate = .1,
              num_leaves = 127,
              max_depth = -1,
              tree_learner = &quot;serial&quot;,
              num_threads = Sys.CPU_THREADS,
              histogram_pool_size = -1.,
              min_data_in_leaf = 100,
              min_sum_hessian_in_leaf = 10.,
              lambda_l1 = 0.,
              lambda_l2 = 0.,
              min_gain_to_split = 0.,
              feature_fraction = 1.,
              feature_fraction_seed = 2,
              bagging_fraction = 1.,
              bagging_freq = 0,
              bagging_seed = 3,
              early_stopping_round = 0,
              max_bin = 255,
              data_random_seed = 1,
              init_score = &quot;&quot;,
              is_sparse = true,
              save_binary = false,
              categorical_feature = Int[],
              sigmoid = 1.,
              is_unbalance = false,
              metric = [&quot;binary_logloss&quot;],
              metric_freq = 1,
              is_training_metric = false,
              ndcg_at = Int[],
              num_machines = 1,
              local_listen_port = 12400,
              time_out = 120,
              machine_list_file = &quot;&quot;,
              device_type=&quot;cpu&quot;,
              random_seed =1])</code></pre><p>Return a LGBMBinary estimator.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/wakakusa/LightGBM.jl/blob/78ace72500bfc8b24878235eda06d16bc4bbf2f7/src/estimators.jl#LL196-L235">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.LGBMMulticlass-Tuple{}" href="#LightGBM.LGBMMulticlass-Tuple{}"><code>LightGBM.LGBMMulticlass</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">LGBMMulticlass(; [num_iterations = 10,
                  learning_rate = .1,
                  num_leaves = 127,
                  max_depth = -1,
                  tree_learner = &quot;serial&quot;,
                  num_threads = Sys.CPU_THREADS,
                  histogram_pool_size = -1.,
                  min_data_in_leaf = 100,
                  min_sum_hessian_in_leaf = 10.,
                  lambda_l1 = 0.,
                  lambda_l2 = 0.,
                  min_gain_to_split = 0.,
                  feature_fraction = 1.,
                  feature_fraction_seed = 2,
                  bagging_fraction = 1.,
                  bagging_freq = 0,
                  bagging_seed = 3,
                  early_stopping_round = 0,
                  max_bin = 255,
                  data_random_seed = 1,
                  init_score = &quot;&quot;,
                  is_sparse = true,
                  save_binary = false,
                  categorical_feature = Int[],
                  is_unbalance = false,
                  metric = [&quot;multi_logloss&quot;],
                  metric_freq = 1,
                  is_training_metric = false,
                  ndcg_at = Int[],
                  num_machines = 1,
                  local_listen_port = 12400,
                  time_out = 120,
                  machine_list_file = &quot;&quot;,
                  num_class = 1,
                  device_type=&quot;cpu&quot;,
                  random_seed=1])</code></pre><p>Return a LGBMMulticlass estimator.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/wakakusa/LightGBM.jl/blob/78ace72500bfc8b24878235eda06d16bc4bbf2f7/src/estimators.jl#LL341-L380">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.LGBMRegression-Tuple{}" href="#LightGBM.LGBMRegression-Tuple{}"><code>LightGBM.LGBMRegression</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">LGBMRegression(; [num_iterations = 10,
                  learning_rate = .1,
                  num_leaves = 127,
                  max_depth = -1,
                  tree_learner = &quot;serial&quot;,
                  num_threads = Sys.CPU_THREADS,
                  histogram_pool_size = -1.,
                  min_data_in_leaf = 100,
                  min_sum_hessian_in_leaf = 10.,
                  lambda_l1 = 0.,
                  lambda_l2 = 0.,
                  min_gain_to_split = 0.,
                  feature_fraction = 1.,
                  feature_fraction_seed = 2,
                  bagging_fraction = 1.,
                  bagging_freq = 0,
                  bagging_seed = 3,
                  early_stopping_round = 0,
                  max_bin = 255,
                  data_random_seed = 1,
                  init_score = &quot;&quot;,
                  is_sparse = true,
                  save_binary = false,
                  categorical_feature = Int[],
                  is_unbalance = false,
                  metric = [&quot;l2&quot;],
                  metric_freq = 1,
                  is_training_metric = false,
                  ndcg_at = Int[],
                  num_machines = 1,
                  local_listen_port = 12400,
                  time_out = 120,
                  machine_list_file = &quot;&quot;,
                 device_type=&quot;cpu&quot;,
                 random_seed = 1])</code></pre><p>Return a LGBMRegression estimator.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/wakakusa/LightGBM.jl/blob/78ace72500bfc8b24878235eda06d16bc4bbf2f7/src/estimators.jl#LL53-L91">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.cv-Union{Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2},Array{Ty,1},Any}} where Ty&lt;:Real where TX&lt;:Real" href="#LightGBM.cv-Union{Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2},Array{Ty,1},Any}} where Ty&lt;:Real where TX&lt;:Real"><code>LightGBM.cv</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">cv(estimator, X, y, splits; [verbosity = 1])</code></pre><p>Cross-validate the <code>estimator</code> with features data <code>X</code> and label <code>y</code>. The iterable <code>splits</code> provides vectors of indices for the training dataset. The remaining indices are used to create the validation dataset.</p><p>Return a dictionary with an entry for the validation dataset and, if the parameter <code>is_training_metric</code> is set in the <code>estimator</code>, an entry for the training dataset. Each entry of the dictionary is another dictionary with an entry for each validation metric in the <code>estimator</code>. Each of these entries is an array that holds the validation metric&#39;s value for each dataset, at the last valid iteration.</p><p><strong>Arguments</strong></p><ul><li><code>estimator::LGBMEstimator</code>: the estimator to be fit.</li><li><code>X::Matrix{TX&lt;:Real}</code>: the features data.</li><li><code>y::Vector{Ty&lt;:Real}</code>: the labels.</li><li><code>splits</code>: the iterable providing arrays of indices for the training dataset.</li><li><code>verbosity::Integer</code>: keyword argument that controls LightGBM&#39;s verbosity. <code>&lt; 0</code> for fatal logs   only, <code>0</code> includes warning logs, <code>1</code> includes info logs, and <code>&gt; 1</code> includes debug logs.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/wakakusa/LightGBM.jl/blob/78ace72500bfc8b24878235eda06d16bc4bbf2f7/src/cv.jl#LL1-L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.fit-Union{Tuple{Ti}, Tuple{Tw}, Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2},Array{Ty,1},Vararg{Tuple{Array{TX,2},Array{Ty,1}},N} where N}} where Ti&lt;:Real where Tw&lt;:Real where Ty&lt;:Real where TX&lt;:Real" href="#LightGBM.fit-Union{Tuple{Ti}, Tuple{Tw}, Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2},Array{Ty,1},Vararg{Tuple{Array{TX,2},Array{Ty,1}},N} where N}} where Ti&lt;:Real where Tw&lt;:Real where Ty&lt;:Real where TX&lt;:Real"><code>LightGBM.fit</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">fit(estimator, X, y[, test...]; [verbosity = 1, is_row_major = false])</code></pre><p>Fit the <code>estimator</code> with features data <code>X</code> and label <code>y</code> using the X-y pairs in <code>test</code> as validation sets.</p><p>Return a dictionary with an entry for each validation set. Each entry of the dictionary is another dictionary with an entry for each validation metric in the <code>estimator</code>. Each of these entries is an array that holds the validation metric&#39;s value at each iteration.</p><p><strong>Arguments</strong></p><ul><li><code>estimator::LGBMEstimator</code>: the estimator to be fit.</li><li><code>X::Matrix{TX&lt;:Real}</code>: the features data.</li><li><code>y::Vector{Ty&lt;:Real}</code>: the labels.</li><li><code>test::Tuple{Matrix{TX},Vector{Ty}}...</code>: optionally contains one or more tuples of X-y pairs of   the same types as <code>X</code> and <code>y</code> that should be used as validation sets.</li><li><code>verbosity::Integer</code>: keyword argument that controls LightGBM&#39;s verbosity. <code>&lt; 0</code> for fatal logs   only, <code>0</code> includes warning logs, <code>1</code> includes info logs, and <code>&gt; 1</code> includes debug logs.</li><li><code>is_row_major::Bool</code>: keyword argument that indicates whether or not <code>X</code> is row-major. <code>true</code>   indicates that it is row-major, <code>false</code> indicates that it is column-major (Julia&#39;s default).</li><li><code>weights::Vector{Tw&lt;:Real}</code>: the training weights.</li><li><code>init_score::Vector{Ti&lt;:Real}</code>: the init scores.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/wakakusa/LightGBM.jl/blob/78ace72500bfc8b24878235eda06d16bc4bbf2f7/src/fit.jl#LL1-L23">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.formattedclassfit-Tuple{Array,Array}" href="#LightGBM.formattedclassfit-Tuple{Array,Array}"><code>LightGBM.formattedclassfit</code></a> — <span class="docstring-category">Method</span></header><section><div><p>formattedclassfit(result::Array,Xtest::Array)  </p><p>予測精度の一番高い結果だけをLightGBM実行形式で出力される形式で出力  </p><p>Only the result with the highest prediction accuracy is output in the output format in the LightGBM execution format  </p><p><strong>Arguments</strong></p><p><code>result::Array</code>:prediction result.   <code>Xtest::Array</code>:the features data.  </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/wakakusa/LightGBM.jl/blob/78ace72500bfc8b24878235eda06d16bc4bbf2f7/src/LightGBM-util2.jl#LL54-L63">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.loadmodel-Tuple{LGBMEstimator,String}" href="#LightGBM.loadmodel-Tuple{LGBMEstimator,String}"><code>LightGBM.loadmodel</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">loadmodel(estimator, filename)</code></pre><p>Load the fitted model <code>filename</code> into <code>estimator</code>. Note that this only loads the fitted model—not the parameters or data of the estimator whose model was saved as <code>filename</code>.</p><p><strong>Arguments</strong></p><ul><li><code>estimator::LGBMEstimator</code>: the estimator to use in the prediction.</li><li><code>filename::String</code>: the name of the file that contains the model.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/wakakusa/LightGBM.jl/blob/78ace72500bfc8b24878235eda06d16bc4bbf2f7/src/utils.jl#LL32-L41">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.metaformattedclassresult-Tuple{Array,Array}" href="#LightGBM.metaformattedclassresult-Tuple{Array,Array}"><code>LightGBM.metaformattedclassresult</code></a> — <span class="docstring-category">Method</span></header><section><div><p>metaformattedclassresult(result::Array,Xtest::Array)  </p><p>LightGBM実行形式で出力される行列フォーマットに変換  </p><p>Converts to matrix format output in LightGBM executable format  </p><p><strong>Arguments</strong></p><p><code>result::Array</code>:prediction   <code>Xtest::Array</code>:the features data.  </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/wakakusa/LightGBM.jl/blob/78ace72500bfc8b24878235eda06d16bc4bbf2f7/src/LightGBM-util2.jl#LL1-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.metaformattedclassresult-Tuple{Array{T,2} where T}" href="#LightGBM.metaformattedclassresult-Tuple{Array{T,2} where T}"><code>LightGBM.metaformattedclassresult</code></a> — <span class="docstring-category">Method</span></header><section><div><p>metaformattedclassresult(metaformattedresult::Array)  </p><p>分類予測結果から、予測精度の一番高い結果だけをLightGBM実行形式で出力される形式で出力  </p><p>From the classification prediction result, only the result with the highest prediction accuracy is output in the output format in the LightGBM execution format  </p><p><strong>Arguments</strong></p><p><code>metaformattedresult::Array</code>:formatted prediction result.  </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/wakakusa/LightGBM.jl/blob/78ace72500bfc8b24878235eda06d16bc4bbf2f7/src/LightGBM-util2.jl#LL27-L35">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.predict-Union{Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2}}} where TX&lt;:Real" href="#LightGBM.predict-Union{Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2}}} where TX&lt;:Real"><code>LightGBM.predict</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">predict(estimator, X; [predict_type = 0, num_iterations = -1, verbosity = 1,
is_row_major = false])</code></pre><p>Return an array with the labels that the <code>estimator</code> predicts for features data <code>X</code>.</p><p><strong>Arguments</strong></p><ul><li><code>estimator::LGBMEstimator</code>: the estimator to use in the prediction.</li><li><code>X::Matrix{T&lt;:Real}</code>: the features data.</li><li><code>predict_type::Integer</code>: keyword argument that controls the prediction type. <code>0</code> for normal   scores with transform (if needed), <code>1</code> for raw scores, <code>2</code> for leaf indices.</li><li><code>num_iterations::Integer</code>: keyword argument that sets the number of iterations of the model to   use in the prediction. <code>&lt; 0</code> for all iterations.</li><li><code>verbosity::Integer</code>: keyword argument that controls LightGBM&#39;s verbosity. <code>&lt; 0</code> for fatal logs   only, <code>0</code> includes warning logs, <code>1</code> includes info logs, and <code>&gt; 1</code> includes debug logs.</li><li><code>is_row_major::Bool</code>: keyword argument that indicates whether or not <code>X</code> is row-major. <code>true</code>   indicates that it is row-major, <code>false</code> indicates that it is column-major (Julia&#39;s default).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/wakakusa/LightGBM.jl/blob/78ace72500bfc8b24878235eda06d16bc4bbf2f7/src/predict.jl#LL2-L19">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.predict2-Union{Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2}}} where TX&lt;:Real" href="#LightGBM.predict2-Union{Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2}}} where TX&lt;:Real"><code>LightGBM.predict2</code></a> — <span class="docstring-category">Method</span></header><section><div><p>predict2(estimator::LGBMEstimator, Xtest::Array)  </p><p>分類予測の場合、予測精度の一番高い結果だけを出力する。その他の予測は結果をそのまま出力  </p><p>In the case of classification prediction, only the result with the highest prediction accuracy is output. Other predictions output the results as they are  </p><p><strong>Arguments</strong></p><ul><li><code>estimator::LGBMEstimator</code>: the estimator to use in the prediction.</li><li><code>X::Matrix{T&lt;:Real}</code>: the features data.</li><li><code>predict_type::Integer</code>: keyword argument that controls the prediction type. <code>0</code> for normal   scores with transform (if needed), <code>1</code> for raw scores, <code>2</code> for leaf indices.</li><li><code>num_iterations::Integer</code>: keyword argument that sets the number of iterations of the model to   use in the prediction. <code>&lt; 0</code> for all iterations.</li><li><code>verbosity::Integer</code>: keyword argument that controls LightGBM&#39;s verbosity. <code>&lt; 0</code> for fatal logs   only, <code>0</code> includes warning logs, <code>1</code> includes info logs, and <code>&gt; 1</code> includes debug logs.</li><li><code>is_row_major::Bool</code>: keyword argument that indicates whether or not <code>X</code> is row-major. <code>true</code>   indicates that it is row-major, <code>false</code> indicates that it is column-major (Julia&#39;s default).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/wakakusa/LightGBM.jl/blob/78ace72500bfc8b24878235eda06d16bc4bbf2f7/src/LightGBM-util2.jl#LL68-L85">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.savemodel-Tuple{LGBMEstimator,String}" href="#LightGBM.savemodel-Tuple{LGBMEstimator,String}"><code>LightGBM.savemodel</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">savemodel(estimator, filename; [num_iteration = -1])</code></pre><p>Save the fitted model in <code>estimator</code> as <code>filename</code>.</p><p><strong>Arguments</strong></p><ul><li><code>estimator::LGBMEstimator</code>: the estimator to use in the prediction.</li><li><code>filename::String</code>: the name of the file to save the model in.</li><li><code>num_iteration::Integer</code>: keyword argument that sets the number of iterations of the model that   should be saved. <code>&lt; 0</code> for all iterations.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/wakakusa/LightGBM.jl/blob/78ace72500bfc8b24878235eda06d16bc4bbf2f7/src/utils.jl#LL15-L25">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.search_cv-Union{Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2},Array{Ty,1},Any,Any}} where Ty&lt;:Real where TX&lt;:Real" href="#LightGBM.search_cv-Union{Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2},Array{Ty,1},Any,Any}} where Ty&lt;:Real where TX&lt;:Real"><code>LightGBM.search_cv</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">search_cv(estimator, X, y, splits, params; [verbosity = 1])</code></pre><p>Exhaustive search over the specified sets of parameter values for the <code>estimator</code> with features data <code>X</code> and label <code>y</code>. The iterable <code>splits</code> provides vectors of indices for the training dataset. The remaining indices are used to create the validation dataset.</p><p>Return an array with a tuple for each set of parameters value, where the first entry is a set of parameter values and the second entry the cross-validation outcome of those values. This outcome is a dictionary with an entry for the validation dataset and, if the parameter <code>is_training_metric</code> is set in the <code>estimator</code>, an entry for the training dataset. Each entry of the dictionary is another dictionary with an entry for each validation metric in the <code>estimator</code>. Each of these entries is an array that holds the validation metric&#39;s value for each dataset, at the last valid iteration.</p><p><strong>Arguments</strong></p><ul><li><code>estimator::LGBMEstimator</code>: the estimator to be fit.</li><li><code>X::Matrix{TX&lt;:Real}</code>: the features data.</li><li><code>y::Vector{Ty&lt;:Real}</code>: the labels.</li><li><code>splits</code>: the iterable providing arrays of indices for the training dataset.</li><li><code>params</code>: the iterable providing dictionaries of pairs of parameters (Symbols) and values to   configure the <code>estimator</code> with.</li><li><code>verbosity::Integer</code>: keyword argument that controls LightGBM&#39;s verbosity. <code>&lt; 0</code> for fatal logs   only, <code>0</code> includes warning logs, <code>1</code> includes info logs, and <code>&gt; 1</code> includes debug logs.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/wakakusa/LightGBM.jl/blob/78ace72500bfc8b24878235eda06d16bc4bbf2f7/src/search_cv.jl#LL1-L25">source</a></section></article></article></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Saturday 25 January 2020 13:32">Saturday 25 January 2020</span>. Using Julia version 1.0.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
